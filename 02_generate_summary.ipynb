{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_date = '2023-03-02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:\n",
      "\n",
      "As a hypothetical expert news aggregator who focuses mainly on banking operations, generate news tags, named entities, sentiment and summary for the following news article. Be honest and output NA if any of the field does not exist or if no news article is given in the input. Use the following format:\n",
      "Tags:\n",
      "Organisation:\n",
      "Named Person:\n",
      "Country:\n",
      "Sentiment (positive/negative/neutral):\n",
      "Concise Summary (without omitting named entities):\n",
      "\n",
      "total number of news articles: 166\n",
      "number of news articles for current run 1\n",
      "number of batches: 0\n",
      "number of extra rows after runs complete, for last batch\n",
      "Created a new dataframe called \"pro_news\" to store values\n",
      "\n",
      "Next part is the CRITICAL PART - note that each run costs $$$, so try to minimise the number of redundant runs\n",
      "If you want to create sample runs, set sample within this block\n"
     ]
    }
   ],
   "source": [
    "# get article embeddings\n",
    "# load libs\n",
    "import tiktoken\n",
    "from openai.embeddings_utils import get_embedding\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# prompt design\n",
    "prompt_gl = \"\\nAs a hypothetical expert news aggregator who focuses mainly on banking operations, generate news tags, named entities, sentiment and summary for the following news article. Be honest and output NA if any of the field does not exist or if no news article is given in the input. Use the following format:\\nTags:\\nOrganisation:\\nNamed Person:\\nCountry:\\nSentiment (positive/negative/neutral):\\nConcise Summary (without omitting named entities):\"\n",
    "print('prompt:\\n' + prompt_gl)\n",
    "\n",
    "\n",
    "# implement retrying library to skip rate limit error\n",
    "import openai  # for OpenAI API calls\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(10))\n",
    "def completion_with_backoff(**kwargs):\n",
    "    return openai.Completion.create(**kwargs)\n",
    "\n",
    "# news factory function with tenacity backoff implemented\n",
    "def news_factoryv2(news_row):\n",
    "\n",
    "    openai.api_key = \"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\"\n",
    "    \n",
    "    content = news_row.full_text\n",
    "    response = completion_with_backoff(\n",
    "    model=\"text-davini-003\",\n",
    "    prompt= content + prompt_gl,\n",
    "    temperature=0, # to prevent entropy\n",
    "    max_tokens=512,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    "    )\n",
    "    text = response['choices'][0]['text'] # get only the text part\n",
    "    #time.sleep(1) # to prevent server error\n",
    "\n",
    "    return text\n",
    "\n",
    "# function to extract details from llm into pd.series \n",
    "def extract_detailsv2(row):\n",
    "    details = {}\n",
    "    for item in row.strip().split('\\n'):\n",
    "        split_item = item.strip().split(':')\n",
    "        if len(split_item) >= 2:\n",
    "            key, value = split_item[:2]\n",
    "            details[key.strip()] = value.strip().strip(\"'\")\n",
    "        else:\n",
    "            print(split_item)\n",
    "            pass\n",
    "    return pd.Series(details)\n",
    "\n",
    "# read headline news 1 feb\n",
    "news_df = pd.read_csv(f'./datasets/ucrawler/{news_date}/{news_date}_rawnews.csv')\n",
    "print('\\ntotal number of news articles: ' + str(len(news_df)))\n",
    "news_df.head(5)\n",
    "\n",
    "# embedding model parameters\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
    "max_tokens = 3000  # the maximum for text-embedding-ada-002 is 8191\n",
    "\n",
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "\n",
    "# omit reviews that are too long to embed\n",
    "news_df[\"n_tokens\"] = news_df.text.apply(lambda x: len(encoding.encode(x)))\n",
    "news_df = news_df[news_df.n_tokens <= max_tokens]\n",
    "\n",
    "##### set sample when doing test runs  #######\n",
    "n = 1\n",
    "print(f'number of news articles for current run {n}')\n",
    "news_df = news_df.sample(n)\n",
    "\n",
    "runs = len(news_df) // 30\n",
    "extra = len(news_df) % 30\n",
    "print(f'number of batches: {runs}')\n",
    "print(f'number of extra rows after runs complete, for last batch')\n",
    "print('Created a new dataframe called \"pro_news\" to store values')\n",
    "pro_news = pd.DataFrame()\n",
    "print('\\nNext part is the CRITICAL PART - note that each run costs $$$, so try to minimise the number of redundant runs')\n",
    "print('If you want to create sample runs, set sample within this block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hang tight, one more batch to go...\n"
     ]
    },
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x28d8899a0 state=finished raised InvalidRequestError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/news_based_alerts/news_alert/lib/python3.9/site-packages/tenacity/__init__.py:409\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    410\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[25], line 27\u001b[0m, in \u001b[0;36mcompletion_with_backoff\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m@retry\u001b[39m(wait\u001b[39m=\u001b[39mwait_random_exponential(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39m\u001b[39m60\u001b[39m), stop\u001b[39m=\u001b[39mstop_after_attempt(\u001b[39m10\u001b[39m))\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompletion_with_backoff\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 27\u001b[0m     \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/news_based_alerts/news_alert/lib/python3.9/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/GitHub/news_based_alerts/news_alert/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:115\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    114\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[0;32m--> 115\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    116\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    117\u001b[0m     url,\n\u001b[1;32m    118\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    119\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    120\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    121\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    122\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    126\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/news_based_alerts/news_alert/lib/python3.9/site-packages/openai/api_requestor.py:181\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    172\u001b[0m     method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    173\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m     request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    180\u001b[0m )\n\u001b[0;32m--> 181\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    182\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Documents/GitHub/news_based_alerts/news_alert/lib/python3.9/site-packages/openai/api_requestor.py:396\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 396\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    397\u001b[0m             result\u001b[39m.\u001b[39;49mcontent, result\u001b[39m.\u001b[39;49mstatus_code, result\u001b[39m.\u001b[39;49mheaders, stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    398\u001b[0m         ),\n\u001b[1;32m    399\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    400\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/news_based_alerts/news_alert/lib/python3.9/site-packages/openai/api_requestor.py:429\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 429\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    430\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    431\u001b[0m     )\n\u001b[1;32m    432\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: That model does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m batch \u001b[39m=\u001b[39m news_df\u001b[39m.\u001b[39miloc[(runs\u001b[39m*\u001b[39m\u001b[39m30\u001b[39m):\u001b[39mlen\u001b[39m(news_df)]\n\u001b[1;32m     23\u001b[0m \u001b[39m# Apply the factory function to each row in the batch\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m batch[\u001b[39m'\u001b[39m\u001b[39mgpt_out\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39;49mapply(news_factoryv2, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     25\u001b[0m pro_news \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([pro_news, batch])\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msuccess!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/news_based_alerts/news_alert/lib/python3.9/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/news_based_alerts/news_alert/lib/python3.9/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/Documents/GitHub/news_based_alerts/news_alert/lib/python3.9/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/Documents/GitHub/news_based_alerts/news_alert/lib/python3.9/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[25], line 35\u001b[0m, in \u001b[0;36mnews_factoryv2\u001b[0;34m(news_row)\u001b[0m\n\u001b[1;32m     32\u001b[0m openai\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msk-Rlo6twBmVUSIeXPa23N1T3BlbkFJTPbaoAiCxRpRBnaxB8d3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m content \u001b[39m=\u001b[39m news_row\u001b[39m.\u001b[39mfull_text\n\u001b[0;32m---> 35\u001b[0m response \u001b[39m=\u001b[39m completion_with_backoff(\n\u001b[1;32m     36\u001b[0m model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-davini-003\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     37\u001b[0m prompt\u001b[39m=\u001b[39;49m content \u001b[39m+\u001b[39;49m prompt_gl,\n\u001b[1;32m     38\u001b[0m temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, \u001b[39m# to prevent entropy\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m max_tokens\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m,\n\u001b[1;32m     40\u001b[0m top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     41\u001b[0m frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     42\u001b[0m presence_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m text \u001b[39m=\u001b[39m response[\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m# get only the text part\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m#time.sleep(1) # to prevent server error\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/news_based_alerts/news_alert/lib/python3.9/site-packages/tenacity/__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/Documents/GitHub/news_based_alerts/news_alert/lib/python3.9/site-packages/tenacity/__init__.py:406\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    405\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    407\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    408\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/GitHub/news_based_alerts/news_alert/lib/python3.9/site-packages/tenacity/__init__.py:363\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m    362\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[0;32m--> 363\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    365\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[1;32m    366\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state\u001b[39m=\u001b[39mretry_state)\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x28d8899a0 state=finished raised InvalidRequestError>]"
     ]
    }
   ],
   "source": [
    "for i in range(0, int(runs)):\n",
    "    \n",
    "    if i == 0:\n",
    "        word = 'first'\n",
    "    else:\n",
    "        word = 'next'\n",
    "    \n",
    "    print(f'running {word} batch.... ' + str(i*30) + ' to ' + str((i+1)*30) + '...')\n",
    "    \n",
    "    batch = news_df.iloc[(i*30):(i+1)*30]\n",
    "    # Apply the factory function to each row in the batch\n",
    "    batch['gpt_out'] = batch.apply(news_factoryv2, axis=1)\n",
    "\n",
    "    pro_news = pd.concat([pro_news, batch])\n",
    "    # Wait for 1 minute before sending the next batch\n",
    "    time.sleep(60)\n",
    "\n",
    "    print('success!')\n",
    "\n",
    "#final ones\n",
    "print('hang tight, one more batch to go...')\n",
    "batch = news_df.iloc[(runs*30):len(news_df)]\n",
    "# Apply the factory function to each row in the batch\n",
    "batch['gpt_out'] = batch.apply(news_factoryv2, axis=1)\n",
    "pro_news = pd.concat([pro_news, batch])\n",
    "\n",
    "print('success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'ChatCompletion'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m      7\u001b[0m   model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m   messages\u001b[39m=\u001b[39m[\n\u001b[1;32m      9\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mYou are a helpful assistant.\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m     10\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mWho won the world series in 2020?\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m     11\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mThe Los Angeles Dodgers won the World Series in 2020.\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m     12\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mWhere was it played?\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     13\u001b[0m     ]\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'ChatCompletion'"
     ]
    }
   ],
   "source": [
    "openai.api_key = \"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\"\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHi there!'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>pub_time</th>\n",
       "      <th>meta_images</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>full_text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>gpt_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>China's CATL sells its stake in Australian lit...</td>\n",
       "      <td>FILE PHOTO: The logo of Chinese battery maker ...</td>\n",
       "      <td>2023-03-02 01:32:43.754000+00:00</td>\n",
       "      <td>https://onecms-res.cloudinary.com/image/upload...</td>\n",
       "      <td>CNA</td>\n",
       "      <td>https://www.channelnewsasia.com/business/china...</td>\n",
       "      <td>China's CATL sells its stake in Australian lit...</td>\n",
       "      <td>177</td>\n",
       "      <td>\\n\\nTags: CATL, Pilbara Minerals Ltd, Goldman ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "116  China's CATL sells its stake in Australian lit...   \n",
       "\n",
       "                                                  text  \\\n",
       "116  FILE PHOTO: The logo of Chinese battery maker ...   \n",
       "\n",
       "                             pub_time  \\\n",
       "116  2023-03-02 01:32:43.754000+00:00   \n",
       "\n",
       "                                           meta_images source  \\\n",
       "116  https://onecms-res.cloudinary.com/image/upload...    CNA   \n",
       "\n",
       "                                                   url  \\\n",
       "116  https://www.channelnewsasia.com/business/china...   \n",
       "\n",
       "                                             full_text  n_tokens  \\\n",
       "116  China's CATL sells its stake in Australian lit...       177   \n",
       "\n",
       "                                               gpt_out  \n",
       "116  \\n\\nTags: CATL, Pilbara Minerals Ltd, Goldman ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of news articles: 1\n",
      "extracting generated fields...\n",
      "saving dataset...\n"
     ]
    }
   ],
   "source": [
    "print('Number of news articles: ' + str(len(pro_news)))\n",
    "\n",
    "# store back-up\n",
    "back_news = pro_news\n",
    "\n",
    "# extract details from column gpt_out and store into new columns\n",
    "print('extracting generated fields...')\n",
    "df_details = pro_news['gpt_out'].apply(extract_detailsv2)\n",
    "\n",
    "df_key = df_details[['Tags', 'Organisation', 'Named Person', 'Country', 'Sentiment', 'Concise Summary']]\n",
    "pro_news = pd.concat([pro_news, df_key], axis=1)\n",
    "\n",
    "# change some column name\n",
    "pro_news.rename(columns={'Concise Summary':'Summary'}, inplace=True)\n",
    "\n",
    "# save dataset\n",
    "print('saving dataset...')\n",
    "path = f'./datasets/ucrawler/{news_date}/{news_date}_ucgpt.csv'\n",
    "pro_news.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>pub_time</th>\n",
       "      <th>meta_images</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>full_text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>gpt_out</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Organisation</th>\n",
       "      <th>Named Person</th>\n",
       "      <th>Country</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>China's CATL sells its stake in Australian lit...</td>\n",
       "      <td>FILE PHOTO: The logo of Chinese battery maker ...</td>\n",
       "      <td>2023-03-02 01:32:43.754000+00:00</td>\n",
       "      <td>https://onecms-res.cloudinary.com/image/upload...</td>\n",
       "      <td>CNA</td>\n",
       "      <td>https://www.channelnewsasia.com/business/china...</td>\n",
       "      <td>China's CATL sells its stake in Australian lit...</td>\n",
       "      <td>177</td>\n",
       "      <td>\\n\\nTags: CATL, Pilbara Minerals Ltd, Goldman ...</td>\n",
       "      <td>CATL, Pilbara Minerals Ltd, Goldman Sachs, UBS</td>\n",
       "      <td>CATL, Pilbara Minerals Ltd, Goldman Sachs, UBS</td>\n",
       "      <td>NA</td>\n",
       "      <td>China, Australia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>CATL, the world's largest battery maker, has s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "116  China's CATL sells its stake in Australian lit...   \n",
       "\n",
       "                                                  text  \\\n",
       "116  FILE PHOTO: The logo of Chinese battery maker ...   \n",
       "\n",
       "                             pub_time  \\\n",
       "116  2023-03-02 01:32:43.754000+00:00   \n",
       "\n",
       "                                           meta_images source  \\\n",
       "116  https://onecms-res.cloudinary.com/image/upload...    CNA   \n",
       "\n",
       "                                                   url  \\\n",
       "116  https://www.channelnewsasia.com/business/china...   \n",
       "\n",
       "                                             full_text  n_tokens  \\\n",
       "116  China's CATL sells its stake in Australian lit...       177   \n",
       "\n",
       "                                               gpt_out  \\\n",
       "116  \\n\\nTags: CATL, Pilbara Minerals Ltd, Goldman ...   \n",
       "\n",
       "                                               Tags  \\\n",
       "116  CATL, Pilbara Minerals Ltd, Goldman Sachs, UBS   \n",
       "\n",
       "                                       Organisation Named Person  \\\n",
       "116  CATL, Pilbara Minerals Ltd, Goldman Sachs, UBS           NA   \n",
       "\n",
       "              Country Sentiment  \\\n",
       "116  China, Australia  Positive   \n",
       "\n",
       "                                               Summary  \n",
       "116  CATL, the world's largest battery maker, has s...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def thing_counter(thing):\n",
    "\n",
    "    pro_news[thing].fillna(\"\", inplace=True)\n",
    "\n",
    "    country_sr = pro_news[thing].apply(lambda x: x.split(','))\n",
    "\n",
    "    # Convert the 'Country' column into a list\n",
    "    country_list = country_sr.tolist()\n",
    "    #print(country_list)\n",
    "    #print(len(country_list))\n",
    "    # Flatten the list of lists into a single list using a list comprehension\n",
    "    flat_list = [item for sublist in country_list for item in sublist]\n",
    "    \n",
    "    #print(flat_list)\n",
    "    if ' Ltd.' in flat_list:\n",
    "        flat_list.remove(' Ltd.')\n",
    "\n",
    "    if 'Ltd.' in flat_list:\n",
    "        flat_list.remove('Ltd.')\n",
    "\n",
    "    if 'N/A' in flat_list:\n",
    "        flat_list.remove('N/A')\n",
    "\n",
    "# follow this script to standardise multiple spellings of the same word\n",
    "    flat_list = ['United States' if x == 'US' else x for x in flat_list]\n",
    "    flat_list = ['United States' if x == ' US' else x for x in flat_list]\n",
    "    flat_list = ['COVID-19' if x == 'Covid-19' else x for x in flat_list]\n",
    "    flat_list = ['COVID-19' if x == ' Covid-19' else x for x in flat_list]\n",
    "\n",
    "    if 'NA' in flat_list:\n",
    "        flat_list.remove('NA')\n",
    "\n",
    "\n",
    "    # Remove the surrounding white spaces from the list\n",
    "    stripped_countries = [country.strip() for country in flat_list]\n",
    "    #print(stripped_countries)\n",
    "    # Create a frequency count of the countries\n",
    "    country_counts = dict(collections.Counter(stripped_countries))\n",
    "\n",
    "    # Create a new dataframe with the country and its count\n",
    "    new_df = pd.DataFrame({thing: list(country_counts.keys()), 'Count': list(country_counts.values())})\n",
    "\n",
    "    new_df = new_df\n",
    "    new_df = new_df[new_df[thing] != '']\n",
    "    new_df = new_df[new_df[thing] != 'NA']\n",
    "    new_df = new_df.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    new_df.Count = new_df['Count'].apply(lambda x: str(x))\n",
    "    new_df[thing + '_count'] = new_df[thing] + ' (' + new_df['Count'] + ')'\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Count</th>\n",
       "      <th>Country_count</th>\n",
       "      <th>Organisation</th>\n",
       "      <th>Count</th>\n",
       "      <th>Organisation_count</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Count</th>\n",
       "      <th>Tags_count</th>\n",
       "      <th>date</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "      <td>China (1)</td>\n",
       "      <td>CATL</td>\n",
       "      <td>1</td>\n",
       "      <td>CATL (1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia (1)</td>\n",
       "      <td>Pilbara Minerals Ltd</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilbara Minerals Ltd (1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>1</td>\n",
       "      <td>Goldman Sachs (1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UBS</td>\n",
       "      <td>1</td>\n",
       "      <td>UBS (1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>tags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country Count  Country_count          Organisation Count  \\\n",
       "0      China     1      China (1)                  CATL     1   \n",
       "1  Australia     1  Australia (1)  Pilbara Minerals Ltd     1   \n",
       "2        NaN   NaN            NaN         Goldman Sachs     1   \n",
       "3        NaN   NaN            NaN                   UBS     1   \n",
       "4        All    NA             NA                   All    NA   \n",
       "\n",
       "         Organisation_count Tags Count Tags_count       date  file  \n",
       "0                  CATL (1)  NaN   NaN        NaN 2023-03-02  tags  \n",
       "1  Pilbara Minerals Ltd (1)  NaN   NaN        NaN 2023-03-02  tags  \n",
       "2         Goldman Sachs (1)  NaN   NaN        NaN 2023-03-02  tags  \n",
       "3                   UBS (1)  NaN   NaN        NaN 2023-03-02  tags  \n",
       "4                        NA  All    NA         NA 2023-03-02  tags  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count countries\n",
    "country_df = thing_counter('Country')\n",
    "country_df = country_df.reset_index(drop=True)\n",
    "country_sm = country_df[0:10]\n",
    "\n",
    "# count organisations\n",
    "org_df = thing_counter('Organisation')\n",
    "org_df = org_df.reset_index(drop=True)\n",
    "org_sm = org_df[0:10]\n",
    "\n",
    "# count keywords\n",
    "keywords_df = thing_counter('Tags')\n",
    "\n",
    "# remove keywords that have already been captured in country and organisation\n",
    "keywords_torem = country_df['Country'].to_list() + org_df['Organisation'].to_list()\n",
    "# Use the isin function to remove the rows in keywords that contain keywords in the list\n",
    "keywords_un = keywords_df[~keywords_df['Tags'].isin(keywords_torem)]\n",
    "# other adhoc keyword removal\n",
    "keywords_un = keywords_un[keywords_un.Tags != 'involuntary manslaughter']\n",
    "keywords_un.reset_index(drop=True, inplace=True)\n",
    "keywords_sm = keywords_un[0:10]\n",
    "\n",
    "# concatenate all dfs\n",
    "tags_df = pd.concat([country_sm, org_sm, keywords_sm], axis=1)\n",
    "\n",
    "# add 'All' column to have it as a parameter field in tableau\n",
    "list_row = ['All', 'NA', 'NA', 'All', 'NA', 'NA', 'All', 'NA', 'NA']\n",
    "tags_df.loc[len(tags_df)] = list_row\n",
    "\n",
    "# add date and file name\n",
    "tags_df['date'] = news_date\n",
    "tags_df['file'] = 'tags'\n",
    "\n",
    "tags_df.date = pd.to_datetime(tags_df.date)\n",
    "\n",
    "tags_df.to_excel(f'./datasets/ucrawler/{news_date}/{news_date}_newstags.xlsx', index=False)\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news_alert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
