{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find relevance scores to given areas of interests. Calculated using cosim similarity and BERT based embeddings\n",
    "def calculate_relevance(news_date, use_current_date = False): # if use_current_date is set to True, given date string is overridden  \n",
    "\n",
    "    # import libraries\n",
    "    import pandas as pd\n",
    "    import openai \n",
    "    import numpy as np\n",
    "    import tiktoken\n",
    "    from openai.embeddings_utils import get_embedding\n",
    "    # ignore warnings\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # if use_current_date is true, run_date for the function is set to current date, else given date\n",
    "    if use_current_date:\n",
    "        current_date = datetime.now().date()\n",
    "        run_date = str(current_date)\n",
    "    else:\n",
    "        run_date = news_date\n",
    "\n",
    "    # path for news data with GPT generated summaries and entities\n",
    "    ucrawler_path = f'./datasets/ucrawler/{news_date}/{news_date}_ucgpt.csv'\n",
    "    unews_df = pd.read_csv(ucrawler_path)\n",
    "    print('total articles in loaded news: ' + str(len(unews_df)))\n",
    "\n",
    "    #df = unews_df\n",
    "    print('removing rows with NA values in Summary')\n",
    "    unews_df.dropna(subset='Summary', inplace=True) # remove rows with NA summaries\n",
    "\n",
    "    # BERT based embeddings\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from openai.embeddings_utils import cosine_similarity\n",
    "    model = SentenceTransformer('multi-qa-distilbert-cos-v1') # different models could be experimented here\n",
    "    # please google for more info on the above model\n",
    "\n",
    "    # function to compute cosine similarity given input\n",
    "    def bert_similar_news(df, search_word, colname, n=5, pprint=False):\n",
    "\n",
    "        # Compute similarity scores between search word and all articles in the Summary column\n",
    "        scores = []\n",
    "        for summary in df['Summary']:\n",
    "            summary_bert = model.encode(summary)\n",
    "            search_bert = model.encode(search_word)\n",
    "            # append score\n",
    "            scores.append(cosine_similarity(search_bert,summary_bert))\n",
    "\n",
    "        # Add similarity scores as a new column to the DataFrame\n",
    "        #colname = colname + '_bert'\n",
    "        df[colname] = scores\n",
    "        \n",
    "        # Sort the DataFrame by similarity scores in descending order\n",
    "        #df.sort_values(by='Similarity Score', ascending=False, inplace=True)\n",
    "\n",
    "        results = (\n",
    "        df.sort_values(colname + '', ascending=False)\n",
    "        .head(n)\n",
    "        .Summary\n",
    "        )\n",
    "        \n",
    "        if pprint:\n",
    "            for r in results:\n",
    "                print(r)\n",
    "                print()\n",
    "\n",
    "        # Return the first n rows of the sorted DataFrame as a list of tuples, where each tuple is a (summary, similarity score) pair\n",
    "        return df[colname]\n",
    "\n",
    "    # your Areas Of Interests (AOI) go here\n",
    "    colnames = ['savings accounts', 'credit cards', 'housing loans', 'wealth', 'SME banking', 'international trade', \n",
    "                'supply chain', 'stock market', 'debt market', 'cryptocurrencies', \n",
    "                'artificial intelligence', 'natural disaster', 'service outage', \n",
    "                'cyber security', 'consumer banking', 'banking regulations', 'fraud and scams']\n",
    "    \n",
    "    cols_keep = list(unews_df.columns) # columns to not melt later when converting to long format (i.e. all columns other than the AOIs)\n",
    "\n",
    "    #news_df = df\n",
    "\n",
    "    print('Running BERT model to calculate news relevance to Areas Of Interests (this might take a few mins, hang tight)')\n",
    "    # Run BERT based model\n",
    "    for i in np.arange(len(colnames)):\n",
    "        unews_df[colnames[i]] = bert_similar_news(unews_df, colnames[i], colnames[i], 1, False)\n",
    "\n",
    "    unews_df.reset_index(inplace=True, drop=True)\n",
    "    unews_df.reset_index(inplace=True)\n",
    "    unews_df['index'] += 1 # make index start from 1\n",
    "\n",
    "    # store wide format df in case\n",
    "    unews_df.to_csv(f'./datasets/ucrawler/{news_date}/{news_date}_cosim.csv', index=False)\n",
    "\n",
    "    # add 'index' column in columns not to melt when converting to long\n",
    "    cols_keep = cols_keep + ['index']\n",
    "\n",
    "    # convert to long\n",
    "    news_dflong = pd.melt(unews_df, id_vars=cols_keep, value_vars=colnames, var_name='tag', value_name='cosim')\n",
    "    # add file column to df\n",
    "    news_dflong['file'] = 'headlines'\n",
    "\n",
    "    print('saving dataset...')\n",
    "    # store results\n",
    "    news_dflong.to_excel(f'./datasets/ucrawler/{news_date}/{news_date}_longcosim.xlsx', index=False)\n",
    "    print('success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_relevance('2023-02-28')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
